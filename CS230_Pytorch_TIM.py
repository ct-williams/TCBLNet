# -*- coding: utf-8 -*-
"""Copy of CS230_Pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lh25_GaIWhR9C5U4cxDnTdfWcHpbCiOM
"""

import os
import torch
import torch.nn as nn
import numpy as np
import h5py
import time

# Load Data
#from google.colab import drive
#drive.mount('/content/drive')


#--------------- USER INPUT -------------------#
modelsave_path = "./networks/NN1.pt"
#----------------------------------------------#




# Set up device
device1 = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#device1 = torch.device('cpu')
device2 = torch.device('cpu')
print(device1)



# Deep Learning Approach

  # Standard Layer Definition
class StandardLayer(nn.Module):
  def __init__(self, n_input_features, n_output_features):
    super(StandardLayer, self).__init__()
    self.lin1 = nn.Linear(n_input_features, n_input_features)
    self.lin2 = nn.Linear(n_input_features, n_output_features)
    self.LRelu = nn.LeakyReLU(0.01)

  def forward(self, x):
    z1 = self.LRelu(self.lin1((x)))
    z2 = self.LRelu(self.lin2(z1)+self.lin2(x))
    return z2

print('defining network')

# Model Definition
Model = nn.Sequential(   # Layer 0
                      StandardLayer(55,40),  # Layer 1
                      StandardLayer(40,40),  # Layer 5
                      StandardLayer(40,40),  # Layer 5
                      StandardLayer(40,20),  # Layer 6
                      StandardLayer(20,20),  # Layer 10
                      StandardLayer(20,20),  # Layer 10
                      StandardLayer(20,10),  # Layer 12
                      StandardLayer(10,10),  # Layer 15
                      StandardLayer(10,10),  # Layer 15
                      StandardLayer(10,10),  # Layer 15
                      nn.Linear(10, 2))      # Layer 11 - Output Layer
Model.double()

# Loss Function 
LossFunction = nn.MSELoss()

# Optimizer 
Optimizer = torch.optim.Adam(Model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.1)

# Send model to device
Model.to(device1)
LossFunction.to(device1)


# Training
num_epochs = 25
num_batches = 900 #1800 #3600
batch_size = 1024 #512 #256
#train_dir = "/content/drive/MyDrive/training_data/training_selection_2/"
train_dir = "../../training_data/training_selection_2_onebatch/"

#### Read data ###
batch = 1
filename = train_dir+"batch_"+ str(batch).zfill(5) + ".hdf"
f = h5py.File(filename, 'r')
data = np.transpose(f['data'])
####

print('training network')

for epoch in range(num_epochs):
  with torch.no_grad():
     norm_error = 0
  tic1 = time.perf_counter()
  for batch in range(1, num_batches+1): 
     if (batch)%100==0:
         print('batch: ', batch)
         toc1 = time.perf_counter()
         print(f"Last 100 batches took {toc1 - tic1:0.4f} seconds")
         tic1 = time.perf_counter()
     # Load data from batch (i) 
#     tic2 = time.perf_counter()
#     filename = train_dir+"batch_"+ str(batch).zfill(5) + ".hdf"
#     f = h5py.File(filename, 'r')
#     data = np.transpose(f['data'])
#     Y = data[:,0:2]
#     X = data[:,2:57]
     ind1 = (batch-1)*batch_size
     ind2 = ind1+batch_size-1
     Y = data[ind1:ind2,0:2]
     X = data[ind1:ind2,2:57]
     # Convert numpy arrays into tensors
     inputs = torch.from_numpy(X)
     labels = torch.from_numpy(Y)
#     toc2 = time.perf_counter()
#     print(f"Loading data {toc2 - tic2:0.4f} seconds")
#     tic2 = time.perf_counter()

     # Send data to the device
     inputs = inputs.to(device1)
     #print(inputs)
     labels = labels.to(device1)
     #labels
#     toc2 = time.perf_counter()
#     print(f"Loading to device {toc2 - tic2:0.4f} seconds")
#     tic2 = time.perf_counter()

     # Forward propagation
     predictions = Model(inputs)
     cost = LossFunction(predictions, labels)
#     toc2 = time.perf_counter()
#     print(f"Forward prop {toc2 - tic2:0.4f} seconds")
#     tic2 = time.perf_counter()
     # Backward propagation
     Optimizer.zero_grad()
     cost.backward()
     Optimizer.step()
     with torch.no_grad():
       norm_error += cost.item()
#     toc2 = time.perf_counter()
#     print(f"Backward prop {toc2 - tic2:0.4f} seconds")
  if (epoch)%5 == 0:
     print("epoch: ",epoch)
     print(norm_error/(num_batches))

# Put model back on CPU for easyness
Model.to(device2)

# SAVE MODEL:
torch.save({
            'epoch': epoch,
            'model_state_dict': Model.state_dict(),
            'optimizer_state_dict': Optimizer.state_dict(),
            }, modelsave_path)

#if read_model_from_path == 1:
#    # Read model from path
#    model = TheModelClass(*args, **kwargs)
#    optimizer = TheOptimizerClass(*args, **kwargs)
#
#    checkpoint = torch.load(PATH)
#    model.load_state_dict(checkpoint['model_state_dict'])
#    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
#    epoch = checkpoint['epoch']
#    loss = checkpoint['loss']
#
#    model.eval()
#    # - or -
#    model.train()
#


# Error Evaluation of Model on Train Data
print('evaluating model on train data')
with torch.no_grad():
   tau_error = 0
   q_error = 0
   for j in range(1, num_batches+1):
      # Load test data from batch (i) into numpy here
      #filename = train_dir+"batch_"+ str(j).zfill(5) + ".hdf"
      #f = h5py.File(filename, 'r')
      #data = np.transpose(f['data'])
      ind1 = (batch-1)*batch_size
      ind2 = ind1+batch_size-1
      Y_tau_np = data[ind1:ind2,0]
      Y_q_np = data[ind1:ind2,1]
      X_np = data[ind1:ind2,2:57]
      X = torch.from_numpy(X_np)
      Y_tau = torch.from_numpy(Y_tau_np)
      Y_q = torch.from_numpy(Y_q_np)
      Y_hat = Model(X)
      Y_tau_hat = Y_hat[:,0]
      Y_q_hat = Y_hat[:,1]
      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))
      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))
   tau_error /= num_batches
   q_error /= num_batches
print("Training q error: ", q_error.item())
print("Training tau error: ", tau_error.item())

# Error Evaluation of Model on Dev Data
print('evaluating model on dev data')
num_dev_batches = 900
#dev_dir = "/content/drive/MyDrive/training_data/test_selection_2/"
#dev_dir = "../../training_data/test_selection_2_onebatch/"
dev_dir = "../../training_data/test_selection_2/"
with torch.no_grad():
   norm_error = 0
   for j in range(1, num_dev_batches+1):
      # Load test data from batch (i) into numpy here
      filename = dev_dir+"batch_"+ str(j).zfill(5) + ".hdf"
      f = h5py.File(filename, 'r')
      data = np.transpose(f['data'])
      Y_tau_np = data[:,0]
      Y_q_np = data[:,1]
      X_np = data[:,2:57]
      X = torch.from_numpy(X_np)
      Y_tau = torch.from_numpy(Y_tau_np)
      Y_q = torch.from_numpy(Y_q_np)
      Y_hat = Model(X)
      Y_tau_hat = Y_hat[:,0]
      Y_q_hat = Y_hat[:,1]
      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))
      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))
   tau_error /= num_dev_batches
   q_error /= num_dev_batches
print("Dev q error: ", q_error.item())
print("Dev tau error: ", tau_error.item())

# Error Evaluation of Model on Test Data
print('evaluating model on test data')
#test_dir = "/content/drive/MyDrive/training_data/test_selection_2/"
#test_dir = "../../training_data/test_selection_2_onebatch/"
test_dir = "../../training_data/test_selection_2/"
with torch.no_grad():
   norm_error = 0
   for j in range(num_dev_batches+1, 2*num_dev_batches+1):
      # Load test data from batch (i) into numpy here
      filename = test_dir+"batch_"+ str(j).zfill(5) + ".hdf"
      f = h5py.File(filename, 'r')
      data = np.transpose(f['data'])
      Y_tau_np = data[:,0]
      Y_q_np = data[:,1]
      X_np = data[:,2:57]
      X = torch.from_numpy(X_np)
      Y_tau = torch.from_numpy(Y_tau_np)
      Y_q = torch.from_numpy(Y_q_np)
      Y_hat = Model(X)
      Y_tau_hat = Y_hat[:,0]
      Y_q_hat = Y_hat[:,1]
      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))
      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))
   tau_error /= num_dev_batches
   q_error /= num_dev_batches
print("Test q error: ", q_error.item())
print("Test tau error: ", tau_error.item())
