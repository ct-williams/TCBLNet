{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS230_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ct-williams/TCBLNet/blob/main/CS230_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ETSfuNDc1WL1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZv6xhCD62T0",
        "outputId": "fcf7d7fd-bf6a-4e6e-e414-fa009757e1e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning Approach\n",
        "\n",
        "  # Standard Layer Definition\n",
        "class StandardLayer(nn.Module):\n",
        "  def __init__(self, n_input_features, n_output_features):\n",
        "    super(StandardLayer, self).__init__()\n",
        "    self.lin1 = nn.Linear(n_input_features, n_input_features)\n",
        "    self.lin2 = nn.Linear(n_input_features, n_output_features)\n",
        "    self.LRelu = nn.LeakyReLU(0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = self.LRelu(self.lin1((x)))\n",
        "    z2 = self.LRelu(self.lin2(z1)+self.lin2(x))\n",
        "    return z2\n",
        "\n",
        "# Model Definition\n",
        "Model = nn.Sequential(   # Layer 0\n",
        "                      StandardLayer(55,40),  # Layer 1\n",
        "                      StandardLayer(40,40),  # Layer 5\n",
        "                      StandardLayer(40,20),  # Layer 6\n",
        "                      StandardLayer(20,20),  # Layer 10\n",
        "                      StandardLayer(20,10),  # Layer 12\n",
        "                      StandardLayer(10,10),  # Layer 15\n",
        "                      nn.Linear(10, 2))      # Layer 11 - Output Layer\n",
        "Model.double()\n",
        "\n",
        "# Loss Function \n",
        "LossFunction = nn.MSELoss()\n",
        "\n",
        "# Optimizer \n",
        "Optimizer = torch.optim.Adam(Model.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)"
      ],
      "metadata": {
        "id": "4DMP2G-d7Taq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epochs = 25\n",
        "num_batches = 3600\n",
        "train_dir = \"/content/drive/MyDrive/training_data/training_selection_2/\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  with torch.no_grad():\n",
        "     norm_error = 0\n",
        "  for batch in range(1, num_batches+1): \n",
        "     # Load data from batch (i) \n",
        "     filename = train_dir+\"batch_\"+ str(batch).zfill(5) + \".hdf\"\n",
        "     f = h5py.File(filename, 'r')\n",
        "     data = np.transpose(f['data'])\n",
        "     Y = data[:,0:2]\n",
        "     X = data[:,2:57]\n",
        "     # Convert numpy arrays into tensors\n",
        "     inputs = torch.from_numpy(X)\n",
        "     labels = torch.from_numpy(Y)\n",
        "     # Forward propagation\n",
        "     predictions = Model(inputs)\n",
        "     cost = LossFunction(predictions, labels)\n",
        "     # Backward propagation\n",
        "     Optimizer.zero_grad()\n",
        "     cost.backward()\n",
        "     Optimizer.step()\n",
        "     with torch.no_grad():\n",
        "       norm_error += cost.item()\n",
        "  if (epoch)%5 == 0:\n",
        "     print(norm_error/(num_batches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-NHJtdgjtOH",
        "outputId": "ba39c87e-02bc-4d61-f37e-b1b7186c403e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62.54079265012157\n",
            "42.825202612716645\n",
            "40.472860997945816\n",
            "39.57347870033841\n",
            "38.97571081749613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Evaluation of Model on Train Data\n",
        "with torch.no_grad():\n",
        "   tau_error = 0\n",
        "   q_error = 0\n",
        "   for j in range(1, num_batches+1):\n",
        "      # Load test data from batch (i) into numpy here\n",
        "      filename = train_dir+\"batch_\"+ str(j).zfill(5) + \".hdf\"\n",
        "      f = h5py.File(filename, 'r')\n",
        "      data = np.transpose(f['data'])\n",
        "      Y_tau_np = data[:,0]\n",
        "      Y_q_np = data[:,1]\n",
        "      X_np = data[:,2:57]\n",
        "      X = torch.from_numpy(X_np)\n",
        "      Y_tau = torch.from_numpy(Y_tau_np)\n",
        "      Y_q = torch.from_numpy(Y_q_np)\n",
        "      Y_hat = Model(X)\n",
        "      Y_tau_hat = Y_hat[:,0]\n",
        "      Y_q_hat = Y_hat[:,1]\n",
        "      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))\n",
        "      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))\n",
        "   tau_error /= num_batches\n",
        "   q_error /= num_batches\n",
        "print(\"Training q error: \", q_error.item())\n",
        "print(\"Training tau error: \", tau_error.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8eeHZQYimXU",
        "outputId": "69f85e8d-7fac-4fb1-b184-b3d1bd0df1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training q error:  0.23550147652738468\n",
            "Training tau error:  0.6796437163914211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Evaluation of Model on Dev Data\n",
        "num_dev_batches = 900\n",
        "dev_dir = \"/content/drive/MyDrive/training_data/test_selection_2/\"\n",
        "with torch.no_grad():\n",
        "   norm_error = 0\n",
        "   for j in range(1, num_dev_batches+1):\n",
        "      # Load test data from batch (i) into numpy here\n",
        "      filename = dev_dir+\"batch_\"+ str(j).zfill(5) + \".hdf\"\n",
        "      f = h5py.File(filename, 'r')\n",
        "      data = np.transpose(f['data'])\n",
        "      Y_tau_np = data[:,0]\n",
        "      Y_q_np = data[:,1]\n",
        "      X_np = data[:,2:57]\n",
        "      X = torch.from_numpy(X_np)\n",
        "      Y_tau = torch.from_numpy(Y_tau_np)\n",
        "      Y_q = torch.from_numpy(Y_q_np)\n",
        "      Y_hat = Model(X)\n",
        "      Y_tau_hat = Y_hat[:,0]\n",
        "      Y_q_hat = Y_hat[:,1]\n",
        "      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))\n",
        "      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))\n",
        "   tau_error /= num_dev_batches\n",
        "   q_error /= num_dev_batches\n",
        "print(\"Dev q error: \", q_error.item())\n",
        "print(\"Dev tau error: \", tau_error.item())"
      ],
      "metadata": {
        "id": "8HsTMMkvFdOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47966f2-310f-40c1-9419-720b16a7c7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev q error:  0.30782937874369015\n",
            "Dev tau error:  0.7826910869954976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Evaluation of Model on Test Data\n",
        "test_dir = \"/content/drive/MyDrive/training_data/test_selection_2/\"\n",
        "with torch.no_grad():\n",
        "   norm_error = 0\n",
        "   for j in range(num_dev_batches+1, 2*num_dev_batches+1):\n",
        "      # Load test data from batch (i) into numpy here\n",
        "      filename = test_dir+\"batch_\"+ str(j).zfill(5) + \".hdf\"\n",
        "      f = h5py.File(filename, 'r')\n",
        "      data = np.transpose(f['data'])\n",
        "      Y_tau_np = data[:,0]\n",
        "      Y_q_np = data[:,1]\n",
        "      X_np = data[:,2:57]\n",
        "      X = torch.from_numpy(X_np)\n",
        "      Y_tau = torch.from_numpy(Y_tau_np)\n",
        "      Y_q = torch.from_numpy(Y_q_np)\n",
        "      Y_hat = Model(X)\n",
        "      Y_tau_hat = Y_hat[:,0]\n",
        "      Y_q_hat = Y_hat[:,1]\n",
        "      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))\n",
        "      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))\n",
        "   tau_error /= num_dev_batches\n",
        "   q_error /= num_dev_batches\n",
        "print(\"Test q error: \", q_error.item())\n",
        "print(\"Test tau error: \", tau_error.item())"
      ],
      "metadata": {
        "id": "HMAyZ-EMjyZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b9283f-ddec-49e1-c5be-39a21c7348d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test q error:  0.31000395016604754\n",
            "Test tau error:  0.7830040029207743\n"
          ]
        }
      ]
    }
  ]
}