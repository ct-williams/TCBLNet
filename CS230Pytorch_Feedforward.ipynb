{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2CS230Pytorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ct-williams/TCBLNet/blob/main/CS230Pytorch_Feedforward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETSfuNDc1WL1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZv6xhCD62T0",
        "outputId": "f42b2539-0da9-44eb-8d39-81a1b7c1ff34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning Approach\n",
        "\n",
        "  # Standard Layer Definition\n",
        "class StandardLayer(nn.Module):\n",
        "  def __init__(self, n_input_features, n_output_features):\n",
        "    super(StandardLayer, self).__init__()\n",
        "    self.lin1 = nn.Linear(n_input_features, n_output_features)\n",
        "    self.LRelu = nn.LeakyReLU(0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = self.LRelu(self.lin1((x)))\n",
        "    return z1\n",
        "\n",
        "# Model Definition\n",
        "Model = nn.Sequential(   # Layer 0\n",
        "                      StandardLayer(55,8),  # Layer 1\n",
        "                      StandardLayer(8,8),  # Layer 6\n",
        "                      StandardLayer(8,6),  # Layer 6\n",
        "                      StandardLayer(6,4),  # Layer 6\n",
        "                      StandardLayer(4,4),  # Layer 6\n",
        "                      nn.Linear(4, 2))      # Layer 11 - Output Layer\n",
        "Model.double()\n",
        "\n",
        "# Loss Function \n",
        "LossFunction = nn.MSELoss()\n",
        "\n",
        "# Optimizer \n",
        "Optimizer = torch.optim.Adam(Model.parameters(), lr=0.005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)"
      ],
      "metadata": {
        "id": "4DMP2G-d7Taq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epochs = 20\n",
        "num_batches = 3600\n",
        "train_dir = \"/content/drive/MyDrive/training_data/training_selection_2/\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  with torch.no_grad():\n",
        "     norm_error = 0\n",
        "  for batch in range(1, num_batches+1): \n",
        "     # Load data from batch (i) \n",
        "     filename = train_dir+\"batch_\"+ str(batch).zfill(5) + \".hdf\"\n",
        "     f = h5py.File(filename, 'r')\n",
        "     data = np.transpose(f['data'])\n",
        "     Y = data[:,0:2]\n",
        "     X = data[:,2:57]\n",
        "     # Convert numpy arrays into tensors\n",
        "     inputs = torch.from_numpy(X)\n",
        "     labels = torch.from_numpy(Y)\n",
        "     # Forward propagation\n",
        "     predictions = Model(inputs)\n",
        "     cost = LossFunction(predictions, labels)\n",
        "     # Backward propagation\n",
        "     Optimizer.zero_grad()\n",
        "     cost.backward()\n",
        "     Optimizer.step()\n",
        "     with torch.no_grad():\n",
        "       norm_error += cost.item()\n",
        "  if (epoch)%5 == 0:\n",
        "     print(norm_error/(num_batches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-NHJtdgjtOH",
        "outputId": "60555d78-c405-4932-8c71-1027a9c9ae7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84.33838150758159\n",
            "41.91086040498419\n",
            "39.288268440251095\n",
            "38.10752627304554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Evaluation of Model on Train Data\n",
        "with torch.no_grad():\n",
        "   tau_error = 0\n",
        "   q_error = 0\n",
        "   for j in range(1, num_batches+1):\n",
        "      # Load test data from batch (i) into numpy here\n",
        "      filename = train_dir+\"batch_\"+ str(j).zfill(5) + \".hdf\"\n",
        "      f = h5py.File(filename, 'r')\n",
        "      data = np.transpose(f['data'])\n",
        "      Y_tau_np = data[:,0]\n",
        "      Y_q_np = data[:,1]\n",
        "      X_np = data[:,2:57]\n",
        "      X = torch.from_numpy(X_np)\n",
        "      Y_tau = torch.from_numpy(Y_tau_np)\n",
        "      Y_q = torch.from_numpy(Y_q_np)\n",
        "      Y_hat = Model(X)\n",
        "      Y_tau_hat = Y_hat[:,0]\n",
        "      Y_q_hat = Y_hat[:,1]\n",
        "      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))\n",
        "      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))\n",
        "   tau_error /= num_batches\n",
        "   q_error /= num_batches\n",
        "print(\"Training q error: \", q_error.item())\n",
        "print(\"Training tau error: \", tau_error.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8eeHZQYimXU",
        "outputId": "7b4de176-de76-4a79-8ee0-403acf7c0969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training q error:  0.2418991100521749\n",
            "Training tau error:  0.29755656911519135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Evaluation of Model on Dev Data\n",
        "num_dev_batches = 900\n",
        "dev_dir = \"/content/drive/MyDrive/training_data/test_selection_2/\"\n",
        "with torch.no_grad():\n",
        "   norm_error = 0\n",
        "   for j in range(1, num_dev_batches+1):\n",
        "      # Load test data from batch (i) into numpy here\n",
        "      filename = dev_dir+\"batch_\"+ str(j).zfill(5) + \".hdf\"\n",
        "      f = h5py.File(filename, 'r')\n",
        "      data = np.transpose(f['data'])\n",
        "      Y_tau_np = data[:,0]\n",
        "      Y_q_np = data[:,1]\n",
        "      X_np = data[:,2:57]\n",
        "      X = torch.from_numpy(X_np)\n",
        "      Y_tau = torch.from_numpy(Y_tau_np)\n",
        "      Y_q = torch.from_numpy(Y_q_np)\n",
        "      Y_hat = Model(X)\n",
        "      Y_tau_hat = Y_hat[:,0]\n",
        "      Y_q_hat = Y_hat[:,1]\n",
        "      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))\n",
        "      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))\n",
        "   tau_error /= num_dev_batches\n",
        "   q_error /= num_dev_batches\n",
        "print(\"Dev q error: \", q_error.item())\n",
        "print(\"Dev tau error: \", tau_error.item())"
      ],
      "metadata": {
        "id": "8HsTMMkvFdOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4792d1a-e10d-4add-902f-40c46838bde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev q error:  0.42103668511364145\n",
            "Dev tau error:  0.569557491354127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error Evaluation of Model on Test Data\n",
        "test_dir = \"/content/drive/MyDrive/training_data/test_selection_2/\"\n",
        "with torch.no_grad():\n",
        "   norm_error = 0\n",
        "   for j in range(num_dev_batches+1, 2*num_dev_batches+1):\n",
        "      # Load test data from batch (i) into numpy here\n",
        "      filename = test_dir+\"batch_\"+ str(j).zfill(5) + \".hdf\"\n",
        "      f = h5py.File(filename, 'r')\n",
        "      data = np.transpose(f['data'])\n",
        "      Y_tau_np = data[:,0]\n",
        "      Y_q_np = data[:,1]\n",
        "      X_np = data[:,2:57]\n",
        "      X = torch.from_numpy(X_np)\n",
        "      Y_tau = torch.from_numpy(Y_tau_np)\n",
        "      Y_q = torch.from_numpy(Y_q_np)\n",
        "      Y_hat = Model(X)\n",
        "      Y_tau_hat = Y_hat[:,0]\n",
        "      Y_q_hat = Y_hat[:,1]\n",
        "      q_error += 2*torch.mean(torch.div(torch.abs(Y_q-Y_q_hat),torch.add(torch.abs(Y_q),torch.abs(Y_q_hat))))\n",
        "      tau_error += 2*torch.mean(torch.div(torch.abs(Y_tau-Y_tau_hat),torch.add(torch.abs(Y_tau),torch.abs(Y_tau_hat))))\n",
        "   tau_error /= num_dev_batches\n",
        "   q_error /= num_dev_batches\n",
        "print(\"Test q error: \", q_error.item())\n",
        "print(\"Test tau error: \", tau_error.item())"
      ],
      "metadata": {
        "id": "HMAyZ-EMjyZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b36d8e-6476-4495-c248-ae57ba410b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test q error:  0.4269427201534269\n",
            "Test tau error:  0.5747365103265736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/training_data/NN13\"\n",
        "torch.save(Model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "iXsQnAVcyWMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}